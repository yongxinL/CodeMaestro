# Token Estimation and Budget Management

**CodeMaestro v1.0.0**
**Purpose:** Guide for estimating, tracking, and managing token usage throughout development lifecycle
**Target:** Software Architects (Phase 2), Senior Developers (Phase 3), QA Leads (Phase 4)

---

## Overview

Token estimation helps predict and manage the computational resources (LLM API tokens) required to complete development tasks using AI assistance. Accurate token estimation enables:

- **Budget Planning:** Allocate token budgets per task/milestone
- **Cost Control:** Prevent unexpected API costs
- **Session Management:** Optimize context window usage
- **Performance Tracking:** Measure actual vs estimated token efficiency
- **Iteration Planning:** Inform future estimations based on historical data

---

## Key Concepts

### What are Tokens?

Tokens are the units of text processed by Large Language Models (LLMs):
- **Input Tokens:** Text sent to the model (prompts, context, code)
- **Output Tokens:** Text generated by the model (responses, code, documentation)
- **Total Tokens:** Input + Output

**Approximation:** ~4 characters = 1 token (English text), ~1 token per line of code

### Session Budget

The maximum token limit per conversation session:
- **Claude Sonnet 4.5:** 1,000,000 tokens (1M context window)
- **Claude Opus 4.5:** 1,000,000 tokens
- **Claude Haiku 4.5:** 200,000 tokens

**Best Practice:** Reserve 20% buffer for overhead → Usable budget: 800K tokens (Sonnet/Opus)

---

## Estimation Methodology

### Phase-Based Estimation

Different phases have different token consumption patterns:

| Phase | Avg. Tokens/Task | Typical Range | Notes |
|-------|------------------|---------------|-------|
| **Phase 1: Requirements** | 5,000 - 15,000 | 3K - 30K | Specification writing, competitive research |
| **Phase 2: Planning** | 10,000 - 30,000 | 5K - 60K | Architecture design, task decomposition |
| **Phase 3: Implementation** | 15,000 - 50,000 | 8K - 100K | Code generation, debugging, testing |
| **Phase 4: Verification** | 8,000 - 20,000 | 5K - 40K | Test generation, analysis, reporting |
| **Phase 5: Release** | 5,000 - 12,000 | 3K - 25K | Documentation, retrospectives |

### Task Complexity Multipliers

Apply multipliers based on task characteristics:

| Complexity Factor | Multiplier | Description |
|-------------------|------------|-------------|
| **Simple** | 1.0x | Single file, <100 LOC, clear requirements |
| **Moderate** | 2.0x | 2-3 files, 100-300 LOC, some ambiguity |
| **Complex** | 3.5x | 4+ files, 300-700 LOC, multiple dependencies |
| **Very Complex** | 5.0x | 5+ files, 700+ LOC, architectural changes |

**Additional Multipliers:**
- **New Technology:** +1.5x (unfamiliar libraries/frameworks)
- **Legacy Code:** +1.3x (working with existing, undocumented code)
- **High Security:** +1.2x (security-critical tasks require extra validation)
- **Performance Critical:** +1.3x (optimization tasks require profiling/testing)

### Estimation Formula

```
Estimated Tokens = Base Estimate × Complexity Multiplier × Additional Multipliers
```

**Example:**
```
Task: Implement user authentication module (JWT)
- Base Estimate: 25,000 tokens (Phase 3 average)
- Complexity: Complex (4 files, 350 LOC) → 3.5x
- High Security: +1.2x

Estimated Tokens = 25,000 × 3.5 × 1.2 = 105,000 tokens
```

---

## Token Budget Allocation

### Session-Level Budgets

**Per session allocation:**
```
Total Session Budget: 1,000,000 tokens (Sonnet 4.5)
- Reserve (20%): 200,000 tokens
- Usable Budget: 800,000 tokens

Recommended Allocation:
- Context Loading (15%): 120,000 tokens
- Task Execution (70%): 560,000 tokens
- Overhead/Debugging (15%): 120,000 tokens
```

### Task-Level Budgets

**Budget categories:**

| Task Type | Token Budget | Rationale |
|-----------|--------------|-----------|
| **Setup/Config** | 5,000 - 15,000 | Minimal code generation |
| **CRUD Operations** | 15,000 - 30,000 | Repetitive patterns, clear structure |
| **Business Logic** | 25,000 - 60,000 | Complex logic, edge cases |
| **API Integration** | 30,000 - 70,000 | External docs, error handling |
| **UI Components** | 20,000 - 50,000 | Styling, interactivity, accessibility |
| **Testing** | 10,000 - 35,000 | Test generation, coverage |
| **Refactoring** | 20,000 - 80,000 | Understanding + restructuring |
| **Bug Fixes** | 8,000 - 40,000 | Debugging, root cause analysis |

### Milestone-Level Budgets

**Aggregate task budgets + buffer:**
```
Milestone Budget = Σ(Task Budgets) × 1.15 (15% buffer for unknowns)
```

---

## Estimation in Phase 2 (Planning)

### When to Estimate

During **Step 2.8: Task File Generation**, estimate tokens for each task:

1. **Analyze task complexity** (file count, LOC, dependencies)
2. **Apply phase baseline** (Phase 3 = 15K-50K average)
3. **Apply multipliers** (complexity, technology, security)
4. **Round to nearest 5K** (e.g., 23K → 25K)
5. **Document rationale** in task file

### Estimation Template

Include in each task file:

```markdown
## Token Estimation

**Estimated Tokens:** 35,000 tokens

**Rationale:**
- **Base Estimate:** 25,000 tokens (Phase 3, moderate complexity)
- **Complexity:** Moderate (3 files, ~200 LOC) → 2.0x
- **Multipliers:**
  - New library (Context7 integration): +1.5x
- **Calculation:** 25,000 × 2.0 × 1.5 = 75,000 → Adjusted to 35,000 (refined based on similar past tasks)

**Breakdown:**
- Code generation: 20,000 tokens
- Testing: 8,000 tokens
- Documentation: 5,000 tokens
- Debugging buffer: 2,000 tokens
```

### Aggregation in Task DAG

Add token column to task tables:

| Task ID | Description | Est. Hours | Est. Tokens | Dependencies | AC Mapping |
|---------|-------------|-----------|-------------|--------------|------------|
| T-1.1.1 | Setup project | 4 | 10,000 | None | AC-1.1 |
| T-1.1.2 | Config DB | 6 | 15,000 | T-1.1.1 | AC-1.2 |
| T-1.1.3 | Auth module | 8 | 35,000 | T-1.1.2 | AC-1.3 |

**Milestone Summary:**
```markdown
**Total Estimated Tokens:** 60,000 tokens
**Recommended Session Model:** Claude Sonnet 4.5 (fits within 800K usable budget)
```

---

## Token Tracking in Phase 3 (Implementation)

### Step 3.3.1c: Session Budget Check

**Before starting task execution:**

```markdown
### Session Budget Check

**Session Budget:** 1,000,000 tokens (Sonnet 4.5)
- Usable: 800,000 tokens
- Current usage: 142,000 tokens (14.2%)
- Remaining: 658,000 tokens

**Task Token Budget:** 35,000 tokens

**Status:** ✅ Sufficient budget (35K < 658K remaining)

**Action:** Proceed with task execution
```

**If insufficient budget:**
```markdown
**Status:** ⚠️ Low budget (only 45K remaining, need 50K)

**Recommendation:**
1. Complete current task (if <45K)
2. Create recovery checkpoint
3. Start new session with handoff
4. Continue from checkpoint
```

### Step 3.3.7: Actual Token Recording

**After task completion:**

```markdown
## Token Usage

**Estimated:** 35,000 tokens
**Actual:** 42,300 tokens
**Variance:** +7,300 tokens (+20.9%)

**Breakdown:**
- Code generation: 24,500 tokens (est. 20,000)
- Testing: 10,200 tokens (est. 8,000)
- Documentation: 5,100 tokens (est. 5,000)
- Debugging: 2,500 tokens (est. 2,000)

**Variance Analysis:**
- Higher debugging time due to unfamiliar library API
- Testing required more edge cases than anticipated
- Documentation was on target

**Lessons Learned:**
- Increase new library multiplier from 1.5x to 1.7x
- Add +20% buffer for unfamiliar APIs
```

### Session Token Summary

**In recovery checkpoint:**
```markdown
## Session Token Metrics

**Session Model:** Claude Sonnet 4.5 (1M context)
**Session Duration:** ~3 hours
**Tasks Completed:** 5/8

**Token Usage:**
- Total Used: 142,000 tokens (14.2% of budget)
- Average per Task: 28,400 tokens
- Remaining Budget: 658,000 tokens

**Efficiency:**
- Estimated Total: 120,000 tokens
- Actual Total: 142,000 tokens
- Variance: +18.3% (within acceptable range)

**Recommendation for Next Session:**
- Continue with Claude Sonnet 4.5
- Remaining 3 tasks (est. 95K tokens) fit within budget
```

---

## Token Metrics in Phase 4 (Verification)

### Evidence Package Section

**Add to `v[X.Y.Z]-evidence.md`:**

```markdown
## Token Efficiency Metrics

**Session Summary:**
- **Model Used:** Claude Sonnet 4.5
- **Total Sessions:** 3
- **Total Tokens:** 387,000 tokens
- **Session Budget Utilization:** 38.7% (efficient)

**Task-Level Performance:**
| Milestone | Tasks | Est. Tokens | Actual Tokens | Variance |
|-----------|-------|-------------|---------------|----------|
| M1: Foundation | 8 | 120,000 | 142,000 | +18.3% |
| M2: Core Features | 12 | 180,000 | 165,000 | -8.3% |
| M3: Advanced | 6 | 90,000 | 80,000 | -11.1% |
| **Total** | **26** | **390,000** | **387,000** | **-0.8%** |

**Analysis:**
- **Overall Accuracy:** Within ±1% (excellent)
- **Early Tasks:** Over-budget (+18%) due to learning curve
- **Later Tasks:** Under-budget (-8 to -11%) due to pattern reuse and improved prompting

**Key Insights:**
- Task complexity multipliers were accurate
- New library multiplier should be increased from 1.5x to 1.7x
- Testing token estimates were consistently accurate
- Documentation token estimates need +10% adjustment

**Cost Efficiency:**
- Estimated Cost: $11.70 (390K tokens @ $3/MTok input + output mixed)
- Actual Cost: $11.61 (387K tokens)
- Savings: $0.09 (accurate estimation prevented over-provisioning)

**Recommendations for Next Project:**
- Apply 1.7x multiplier for new libraries
- Increase documentation estimates by 10%
- Maintain current complexity multipliers (working well)
```

---

## Token Retrospective in Phase 5 (Release)

### Lessons Learned Section

**Add to `lessons-learned.md`:**

```markdown
## Token Management Lessons

### What Went Well

1. **Estimation Accuracy:**
   - Final variance: -0.8% (390K estimated vs 387K actual)
   - Milestone-level estimates were within ±20%
   - Task-level estimates improved over time (learning effect)

2. **Session Management:**
   - Never exceeded session budget (max utilization: 42%)
   - Effective use of recovery checkpoints
   - Minimal context thrashing

3. **Cost Predictability:**
   - Accurate cost forecasting ($11.70 est. vs $11.61 actual)
   - No budget overruns
   - Enabled confident ROI planning

### What Could Improve

1. **Early Task Estimates:**
   - M1 tasks were +18% over budget
   - Learning curve not adequately accounted for
   - **Action:** Add "project startup" multiplier (1.2x) for first 3-5 tasks

2. **New Library Integration:**
   - 1.5x multiplier was insufficient
   - Actual required 1.7x-1.8x
   - **Action:** Update multiplier to 1.7x in token-estimation.md

3. **Documentation Token Estimates:**
   - Consistently under-estimated by ~10%
   - Complex projects require more thorough docs
   - **Action:** Increase documentation baseline by 10%

### Process Improvements

1. **Add Token Checkpoints:**
   - Check budget before starting each task (Step 3.3.1c) ✅
   - Alert at 80% budget utilization
   - Recommend session break at 85%

2. **Historical Data Collection:**
   - Log all task-level actuals to knowledge base
   - Build project-specific baselines
   - Use past data to refine future estimates

3. **Real-Time Tracking:**
   - Display token usage in recovery checkpoint ✅
   - Show variance trends during implementation
   - Provide session-end token summary

### Recommendations for Future Projects

| Recommendation | Rationale | Impact |
|----------------|-----------|--------|
| Apply 1.7x multiplier for new libs | 1.5x was insufficient | Higher estimation accuracy |
| Add 1.2x "startup" multiplier for M1 | Learning curve effect | Better early-phase estimates |
| Increase doc baseline by 10% | Consistent under-estimation | Accurate doc token budgets |
| Build project-type baselines | Domain-specific patterns | Faster, more accurate estimates |
| Log actuals to KB automatically | Enable ML-based estimation | Continuous improvement |

### Token Efficiency Score

**Overall Score:** 8.5/10

**Breakdown:**
- Estimation Accuracy (30%): 9.5/10 (within ±1%)
- Budget Management (25%): 9.0/10 (never exceeded, minimal waste)
- Cost Predictability (20%): 9.5/10 (accurate forecasting)
- Session Optimization (15%): 7.5/10 (some sessions under-utilized)
- Learning Adaptation (10%): 7.0/10 (slow adjustment in M1)

**Interpretation:**
- **Excellent (9-10):** Estimation accuracy, cost control
- **Good (7-8):** Session optimization, learning adaptation
- **Target for Next Project:** 9.0/10 overall
```

---

## Commands Reference

### `/estimate` - Estimate Token Usage

**Usage:**
```bash
/estimate task T-1.2.3          # Estimate specific task
/estimate milestone M2          # Estimate entire milestone
/estimate session               # Check current session budget status
```

**Output:**
```
Task T-1.2.3: Implement Authentication Module

Estimated Tokens: 35,000 tokens

Breakdown:
- Code generation: 20,000 tokens
- Testing: 8,000 tokens
- Documentation: 5,000 tokens
- Debugging buffer: 2,000 tokens

Complexity: Complex (3.5x)
Multipliers: High Security (+1.2x)

Session Impact:
- Current usage: 142,000 tokens
- After task: ~177,000 tokens (17.7% of budget)
- Status: ✅ Sufficient budget
```

### `/budget` - Check Session Budget

**Usage:**
```bash
/budget                         # Show current session status
/budget --detailed              # Include task-level breakdown
/budget --forecast              # Forecast remaining tasks
```

**Output:**
```
Session Budget Status

Model: Claude Sonnet 4.5 (1M context)
Duration: 2h 15m

Token Usage:
- Used: 142,000 tokens (14.2%)
- Reserved: 200,000 tokens (20%)
- Available: 658,000 tokens (65.8%)

Remaining Tasks: 3
- T-2.1.1: 25,000 tokens (est.)
- T-2.1.2: 30,000 tokens (est.)
- T-2.1.3: 40,000 tokens (est.)
- Total: 95,000 tokens

Forecast:
- After completion: 237,000 tokens used (23.7%)
- Status: ✅ All tasks fit within budget
- Recommendation: Continue in current session
```

### `/variance` - Analyze Token Variance

**Usage:**
```bash
/variance                       # Overall variance analysis
/variance milestone M2          # Milestone-specific analysis
/variance task T-1.2.3          # Task-specific analysis
```

**Output:**
```
Token Variance Analysis

Overall:
- Estimated: 390,000 tokens
- Actual: 387,000 tokens
- Variance: -3,000 tokens (-0.8%)
- Accuracy: Excellent ✅

By Milestone:
M1: +18.3% (over-budget, learning curve)
M2: -8.3% (under-budget, pattern reuse)
M3: -11.1% (under-budget, optimization)

By Phase:
Phase 2 (Planning): +5.2%
Phase 3 (Implementation): -2.1%
Phase 4 (Verification): -4.5%

Trends:
- Improving accuracy over time ✅
- Early estimates too conservative
- Testing estimates accurate
- Documentation under-estimated by ~10%

Recommendations:
1. Apply 1.7x multiplier for new libraries
2. Add 10% to documentation baselines
3. Use historical data for future projects
```

---

## Best Practices

### For Software Architects (Phase 2)

1. **Estimate Early:** Include token estimates in task decomposition
2. **Document Rationale:** Explain complexity factors and multipliers
3. **Aggregate Wisely:** Add 15% buffer at milestone level
4. **Review Historical Data:** Check knowledge base for similar tasks
5. **Communicate Budgets:** Make token budgets visible in task files

### For Senior Developers (Phase 3)

1. **Check Budget First:** Run `/budget` before starting each task (Step 3.3.1c)
2. **Track Actuals:** Record actual token usage after task completion (Step 3.3.7)
3. **Analyze Variance:** Understand why estimates differed from actuals
4. **Update Checkpoints:** Include token metrics in recovery checkpoints
5. **Optimize Prompts:** Reuse patterns to reduce token consumption

### For QA Leads (Phase 4)

1. **Include Token Metrics:** Add token analysis to evidence package
2. **Evaluate Efficiency:** Assess token efficiency as quality metric
3. **Identify Trends:** Spot patterns in token usage across milestones
4. **Calculate ROI:** Estimate cost savings from accurate estimation
5. **Document Learnings:** Capture insights for future projects

### For Release Managers (Phase 5)

1. **Retrospective Analysis:** Include token lessons in lessons-learned
2. **Update Knowledge Base:** Log actual vs estimated for pattern recognition
3. **Refine Multipliers:** Adjust estimation formulas based on outcomes
4. **Publish Benchmarks:** Share token efficiency metrics with team
5. **Plan Future Budgets:** Use actuals to inform next project estimates

---

## Token Optimization Strategies

### Code Reuse
- **Pattern Libraries:** Reuse code patterns from knowledge base (-30% tokens)
- **Template Usage:** Leverage CodeMaestro templates (-40% tokens)
- **Component Reuse:** Reference existing modules instead of regenerating

### Context Management
- **Lazy Loading:** Load templates only when needed (-50% context tokens)
- **Progressive Disclosure:** Use on-demand documentation loading
- **Session Splitting:** Break at logical boundaries to reset context

### Prompt Engineering
- **Specific Instructions:** Reduce back-and-forth iterations (-20% tokens)
- **Constraint References:** Use IDs (A1, B15) instead of full text (-60% tokens)
- **Template References:** Link to templates instead of inlining (-70% tokens)

### Knowledge Base Usage
- **Learn from Past:** Reference previous solutions (-25% tokens)
- **Pattern Matching:** Apply proven approaches (-35% tokens)
- **Failure Avoidance:** Learn from logged failures (-40% debugging tokens)

---

## Troubleshooting

### Issue: Token Estimates Consistently Too Low

**Symptoms:**
- Variance > +25% across multiple tasks
- Session budget exhausted before completion

**Root Causes:**
1. Complexity multipliers too conservative
2. New technology learning curve not accounted for
3. Debugging buffer insufficient

**Solutions:**
- Increase complexity multipliers by 0.5x
- Add "new technology" multiplier (1.7x)
- Increase debugging buffer from 10% to 20%

### Issue: Token Estimates Consistently Too High

**Symptoms:**
- Variance < -20% across multiple tasks
- Session budget under-utilized (<40%)

**Root Causes:**
1. Over-conservative baseline estimates
2. Efficient prompt engineering reducing usage
3. Pattern reuse from knowledge base

**Solutions:**
- Reduce baseline estimates by 15%
- Adjust complexity multipliers down by 0.3x
- Document efficiency gains in KB for future reference

### Issue: Session Budget Exceeded Mid-Task

**Symptoms:**
- Task incomplete, session context limit reached
- Unable to complete current work

**Solutions:**
1. **Immediate:** Create recovery checkpoint with current progress
2. **Immediate:** Document partial completion in task file
3. **Next Session:** Resume from checkpoint with fresh budget
4. **Future:** Increase task buffer from 15% to 25% for complex tasks

---

## Appendix A: Token Estimation Cheat Sheet

| Task Type | Base Tokens | Complexity | Multipliers |
|-----------|-------------|------------|-------------|
| Setup/Config | 5K - 15K | Simple (1.0x) | - |
| CRUD Operations | 15K - 30K | Moderate (2.0x) | - |
| Business Logic | 25K - 60K | Complex (3.5x) | High Security (+1.2x) |
| API Integration | 30K - 70K | Complex (3.5x) | New Library (+1.7x) |
| UI Components | 20K - 50K | Moderate (2.0x) | Accessibility (+1.1x) |
| Testing | 10K - 35K | Moderate (2.0x) | - |
| Refactoring | 20K - 80K | Very Complex (5.0x) | Legacy Code (+1.3x) |
| Bug Fixes | 8K - 40K | Varies | - |

**Quick Formula:**
```
Tokens = Base × Complexity × (1 + Σ Multiplier%)
```

---

## Appendix B: Historical Token Data Format

**Store in knowledge base:**
```markdown
# Task Token History

## T-1.2.3: Implement Authentication Module

**Project:** Project Alpha
**Date:** 2026-01-15
**Phase:** 3 (Implementation)

**Estimate:** 35,000 tokens
**Actual:** 42,300 tokens
**Variance:** +20.9%

**Characteristics:**
- Files: 3 (auth-controller.ts, auth-service.ts, auth-middleware.ts)
- LOC: 285
- Complexity: Complex (3.5x)
- Technology: NestJS (new to team, +1.5x multiplier - should have been 1.7x)
- Security: High (+1.2x)

**Breakdown:**
- Code generation: 24,500 tokens (20,000 est.) - +22.5%
- Testing: 10,200 tokens (8,000 est.) - +27.5%
- Documentation: 5,100 tokens (5,000 est.) - +2%
- Debugging: 2,500 tokens (2,000 est.) - +25%

**Lessons:**
- New library multiplier should be 1.7x (not 1.5x)
- Testing required more edge cases (JWT expiration, refresh tokens)
- Debugging took longer due to passport.js integration issues

**Tags:** #authentication #jwt #nestjs #new-library #complex
```

---

## Version

**Token Estimation Guide Version:** 1.0
**CodeMaestro:** v1.0.0
**Last Updated:** 2026-01-16
